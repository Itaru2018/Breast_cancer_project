{
 "cells": [
  {
   "metadata": {
    "trusted": true
   },
   "cell_type": "code",
   "source": "# Import pandas\nimport pandas as pd",
   "execution_count": 1,
   "outputs": []
  },
  {
   "metadata": {
    "trusted": true
   },
   "cell_type": "code",
   "source": "# Import the dataset\ndf = pd.read_csv('wdbc.data')",
   "execution_count": 2,
   "outputs": []
  },
  {
   "metadata": {
    "trusted": true
   },
   "cell_type": "code",
   "source": "# Check the head of the data\ndf.head()\n",
   "execution_count": 3,
   "outputs": [
    {
     "output_type": "execute_result",
     "execution_count": 3,
     "data": {
      "text/plain": "     842302  M  17.99  10.38   122.8    1001   0.1184   0.2776  0.3001  \\\n0    842517  M  20.57  17.77  132.90  1326.0  0.08474  0.07864  0.0869   \n1  84300903  M  19.69  21.25  130.00  1203.0  0.10960  0.15990  0.1974   \n2  84348301  M  11.42  20.38   77.58   386.1  0.14250  0.28390  0.2414   \n3  84358402  M  20.29  14.34  135.10  1297.0  0.10030  0.13280  0.1980   \n4    843786  M  12.45  15.70   82.57   477.1  0.12780  0.17000  0.1578   \n\n    0.1471  ...  25.38  17.33   184.6    2019  0.1622  0.6656  0.7119  0.2654  \\\n0  0.07017  ...  24.99  23.41  158.80  1956.0  0.1238  0.1866  0.2416  0.1860   \n1  0.12790  ...  23.57  25.53  152.50  1709.0  0.1444  0.4245  0.4504  0.2430   \n2  0.10520  ...  14.91  26.50   98.87   567.7  0.2098  0.8663  0.6869  0.2575   \n3  0.10430  ...  22.54  16.67  152.20  1575.0  0.1374  0.2050  0.4000  0.1625   \n4  0.08089  ...  15.47  23.75  103.40   741.6  0.1791  0.5249  0.5355  0.1741   \n\n   0.4601   0.1189  \n0  0.2750  0.08902  \n1  0.3613  0.08758  \n2  0.6638  0.17300  \n3  0.2364  0.07678  \n4  0.3985  0.12440  \n\n[5 rows x 32 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>842302</th>\n      <th>M</th>\n      <th>17.99</th>\n      <th>10.38</th>\n      <th>122.8</th>\n      <th>1001</th>\n      <th>0.1184</th>\n      <th>0.2776</th>\n      <th>0.3001</th>\n      <th>0.1471</th>\n      <th>...</th>\n      <th>25.38</th>\n      <th>17.33</th>\n      <th>184.6</th>\n      <th>2019</th>\n      <th>0.1622</th>\n      <th>0.6656</th>\n      <th>0.7119</th>\n      <th>0.2654</th>\n      <th>0.4601</th>\n      <th>0.1189</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>842517</td>\n      <td>M</td>\n      <td>20.57</td>\n      <td>17.77</td>\n      <td>132.90</td>\n      <td>1326.0</td>\n      <td>0.08474</td>\n      <td>0.07864</td>\n      <td>0.0869</td>\n      <td>0.07017</td>\n      <td>...</td>\n      <td>24.99</td>\n      <td>23.41</td>\n      <td>158.80</td>\n      <td>1956.0</td>\n      <td>0.1238</td>\n      <td>0.1866</td>\n      <td>0.2416</td>\n      <td>0.1860</td>\n      <td>0.2750</td>\n      <td>0.08902</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>84300903</td>\n      <td>M</td>\n      <td>19.69</td>\n      <td>21.25</td>\n      <td>130.00</td>\n      <td>1203.0</td>\n      <td>0.10960</td>\n      <td>0.15990</td>\n      <td>0.1974</td>\n      <td>0.12790</td>\n      <td>...</td>\n      <td>23.57</td>\n      <td>25.53</td>\n      <td>152.50</td>\n      <td>1709.0</td>\n      <td>0.1444</td>\n      <td>0.4245</td>\n      <td>0.4504</td>\n      <td>0.2430</td>\n      <td>0.3613</td>\n      <td>0.08758</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>84348301</td>\n      <td>M</td>\n      <td>11.42</td>\n      <td>20.38</td>\n      <td>77.58</td>\n      <td>386.1</td>\n      <td>0.14250</td>\n      <td>0.28390</td>\n      <td>0.2414</td>\n      <td>0.10520</td>\n      <td>...</td>\n      <td>14.91</td>\n      <td>26.50</td>\n      <td>98.87</td>\n      <td>567.7</td>\n      <td>0.2098</td>\n      <td>0.8663</td>\n      <td>0.6869</td>\n      <td>0.2575</td>\n      <td>0.6638</td>\n      <td>0.17300</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>84358402</td>\n      <td>M</td>\n      <td>20.29</td>\n      <td>14.34</td>\n      <td>135.10</td>\n      <td>1297.0</td>\n      <td>0.10030</td>\n      <td>0.13280</td>\n      <td>0.1980</td>\n      <td>0.10430</td>\n      <td>...</td>\n      <td>22.54</td>\n      <td>16.67</td>\n      <td>152.20</td>\n      <td>1575.0</td>\n      <td>0.1374</td>\n      <td>0.2050</td>\n      <td>0.4000</td>\n      <td>0.1625</td>\n      <td>0.2364</td>\n      <td>0.07678</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>843786</td>\n      <td>M</td>\n      <td>12.45</td>\n      <td>15.70</td>\n      <td>82.57</td>\n      <td>477.1</td>\n      <td>0.12780</td>\n      <td>0.17000</td>\n      <td>0.1578</td>\n      <td>0.08089</td>\n      <td>...</td>\n      <td>15.47</td>\n      <td>23.75</td>\n      <td>103.40</td>\n      <td>741.6</td>\n      <td>0.1791</td>\n      <td>0.5249</td>\n      <td>0.5355</td>\n      <td>0.1741</td>\n      <td>0.3985</td>\n      <td>0.12440</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows Ã— 32 columns</p>\n</div>"
     },
     "metadata": {}
    }
   ]
  },
  {
   "metadata": {
    "trusted": true
   },
   "cell_type": "code",
   "source": "# Check the information of the dataset\ndf.info()",
   "execution_count": 4,
   "outputs": [
    {
     "output_type": "stream",
     "text": "<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 568 entries, 0 to 567\nData columns (total 32 columns):\n #   Column    Non-Null Count  Dtype  \n---  ------    --------------  -----  \n 0   842302    568 non-null    int64  \n 1   M         568 non-null    object \n 2   17.99     568 non-null    float64\n 3   10.38     568 non-null    float64\n 4   122.8     568 non-null    float64\n 5   1001      568 non-null    float64\n 6   0.1184    568 non-null    float64\n 7   0.2776    568 non-null    float64\n 8   0.3001    568 non-null    float64\n 9   0.1471    568 non-null    float64\n 10  0.2419    568 non-null    float64\n 11  0.07871   568 non-null    float64\n 12  1.095     568 non-null    float64\n 13  0.9053    568 non-null    float64\n 14  8.589     568 non-null    float64\n 15  153.4     568 non-null    float64\n 16  0.006399  568 non-null    float64\n 17  0.04904   568 non-null    float64\n 18  0.05373   568 non-null    float64\n 19  0.01587   568 non-null    float64\n 20  0.03003   568 non-null    float64\n 21  0.006193  568 non-null    float64\n 22  25.38     568 non-null    float64\n 23  17.33     568 non-null    float64\n 24  184.6     568 non-null    float64\n 25  2019      568 non-null    float64\n 26  0.1622    568 non-null    float64\n 27  0.6656    568 non-null    float64\n 28  0.7119    568 non-null    float64\n 29  0.2654    568 non-null    float64\n 30  0.4601    568 non-null    float64\n 31  0.1189    568 non-null    float64\ndtypes: float64(30), int64(1), object(1)\nmemory usage: 142.1+ KB\n",
     "name": "stdout"
    }
   ]
  },
  {
   "metadata": {
    "trusted": true
   },
   "cell_type": "code",
   "source": "# Without the label, it's hard to see what is happeing in this dataset. So I'm goint to import the label of the dataset\n# It doesn't seem the label file is csv file. So firts, load it as a plain file.\nwith open('wdbc.names', 'r') as file:\n    plaindata = file.read()\nprint(plaindata)",
   "execution_count": 5,
   "outputs": [
    {
     "output_type": "stream",
     "text": "1. Title: Wisconsin Diagnostic Breast Cancer (WDBC)\n\n2. Source Information\n\na) Creators: \n\n\tDr. William H. Wolberg, General Surgery Dept., University of\n\tWisconsin,  Clinical Sciences Center, Madison, WI 53792\n\twolberg@eagle.surgery.wisc.edu\n\n\tW. Nick Street, Computer Sciences Dept., University of\n\tWisconsin, 1210 West Dayton St., Madison, WI 53706\n\tstreet@cs.wisc.edu  608-262-6619\n\n\tOlvi L. Mangasarian, Computer Sciences Dept., University of\n\tWisconsin, 1210 West Dayton St., Madison, WI 53706\n\tolvi@cs.wisc.edu \n\nb) Donor: Nick Street\n\nc) Date: November 1995\n\n3. Past Usage:\n\nfirst usage:\n\n\tW.N. Street, W.H. Wolberg and O.L. Mangasarian \n\tNuclear feature extraction for breast tumor diagnosis.\n\tIS&T/SPIE 1993 International Symposium on Electronic Imaging: Science\n\tand Technology, volume 1905, pages 861-870, San Jose, CA, 1993.\n\nOR literature:\n\n\tO.L. Mangasarian, W.N. Street and W.H. Wolberg. \n\tBreast cancer diagnosis and prognosis via linear programming. \n\tOperations Research, 43(4), pages 570-577, July-August 1995.\n\nMedical literature:\n\n\tW.H. Wolberg, W.N. Street, and O.L. Mangasarian. \n\tMachine learning techniques to diagnose breast cancer from\n\tfine-needle aspirates.  \n\tCancer Letters 77 (1994) 163-171.\n\n\tW.H. Wolberg, W.N. Street, and O.L. Mangasarian. \n\tImage analysis and machine learning applied to breast cancer\n\tdiagnosis and prognosis.  \n\tAnalytical and Quantitative Cytology and Histology, Vol. 17\n\tNo. 2, pages 77-87, April 1995. \n\n\tW.H. Wolberg, W.N. Street, D.M. Heisey, and O.L. Mangasarian. \n\tComputerized breast cancer diagnosis and prognosis from fine\n\tneedle aspirates.  \n\tArchives of Surgery 1995;130:511-516.\n\n\tW.H. Wolberg, W.N. Street, D.M. Heisey, and O.L. Mangasarian. \n\tComputer-derived nuclear features distinguish malignant from\n\tbenign breast cytology.  \n\tHuman Pathology, 26:792--796, 1995.\n\nSee also:\n\thttp://www.cs.wisc.edu/~olvi/uwmp/mpml.html\n\thttp://www.cs.wisc.edu/~olvi/uwmp/cancer.html\n\nResults:\n\n\t- predicting field 2, diagnosis: B = benign, M = malignant\n\t- sets are linearly separable using all 30 input features\n\t- best predictive accuracy obtained using one separating plane\n\t\tin the 3-D space of Worst Area, Worst Smoothness and\n\t\tMean Texture.  Estimated accuracy 97.5% using repeated\n\t\t10-fold crossvalidations.  Classifier has correctly\n\t\tdiagnosed 176 consecutive new patients as of November\n\t\t1995. \n\n4. Relevant information\n\n\tFeatures are computed from a digitized image of a fine needle\n\taspirate (FNA) of a breast mass.  They describe\n\tcharacteristics of the cell nuclei present in the image.\n\tA few of the images can be found at\n\thttp://www.cs.wisc.edu/~street/images/\n\n\tSeparating plane described above was obtained using\n\tMultisurface Method-Tree (MSM-T) [K. P. Bennett, \"Decision Tree\n\tConstruction Via Linear Programming.\" Proceedings of the 4th\n\tMidwest Artificial Intelligence and Cognitive Science Society,\n\tpp. 97-101, 1992], a classification method which uses linear\n\tprogramming to construct a decision tree.  Relevant features\n\twere selected using an exhaustive search in the space of 1-4\n\tfeatures and 1-3 separating planes.\n\n\tThe actual linear program used to obtain the separating plane\n\tin the 3-dimensional space is that described in:\n\t[K. P. Bennett and O. L. Mangasarian: \"Robust Linear\n\tProgramming Discrimination of Two Linearly Inseparable Sets\",\n\tOptimization Methods and Software 1, 1992, 23-34].\n\n\n\tThis database is also available through the UW CS ftp server:\n\n\tftp ftp.cs.wisc.edu\n\tcd math-prog/cpo-dataset/machine-learn/WDBC/\n\n5. Number of instances: 569 \n\n6. Number of attributes: 32 (ID, diagnosis, 30 real-valued input features)\n\n7. Attribute information\n\n1) ID number\n2) Diagnosis (M = malignant, B = benign)\n3-32)\n\nTen real-valued features are computed for each cell nucleus:\n\n\ta) radius (mean of distances from center to points on the perimeter)\n\tb) texture (standard deviation of gray-scale values)\n\tc) perimeter\n\td) area\n\te) smoothness (local variation in radius lengths)\n\tf) compactness (perimeter^2 / area - 1.0)\n\tg) concavity (severity of concave portions of the contour)\n\th) concave points (number of concave portions of the contour)\n\ti) symmetry \n\tj) fractal dimension (\"coastline approximation\" - 1)\n\nSeveral of the papers listed above contain detailed descriptions of\nhow these features are computed. \n\nThe mean, standard error, and \"worst\" or largest (mean of the three\nlargest values) of these features were computed for each image,\nresulting in 30 features.  For instance, field 3 is Mean Radius, field\n13 is Radius SE, field 23 is Worst Radius.\n\nAll feature values are recoded with four significant digits.\n\n8. Missing attribute values: none\n\n9. Class distribution: 357 benign, 212 malignant\n",
     "name": "stdout"
    }
   ]
  },
  {
   "metadata": {
    "trusted": true
   },
   "cell_type": "code",
   "source": "# Create the feature names according to the description\n# Define the base feature name\nfeatures = ['radius', 'texture', 'perimeter', 'area', 'smoothness', 'compactness', 'concavity', 'concave_points', 'symmetry', 'fractal dimension']\n\n# Check the size of the list so that I don't miss any features\nlen(features)",
   "execution_count": 6,
   "outputs": [
    {
     "output_type": "execute_result",
     "execution_count": 6,
     "data": {
      "text/plain": "10"
     },
     "metadata": {}
    }
   ]
  },
  {
   "metadata": {
    "trusted": true
   },
   "cell_type": "code",
   "source": "# Define the full feature names\nfeature_names = ['ID', 'Diagnostic'] + [f'{feature}_mean' for feature in features] + [f'{feature}_SE' for feature in features] + [f'{feature}_worst' for feature in features]\n\n# Check the size of the feature\nlen(feature_names)\n",
   "execution_count": 7,
   "outputs": [
    {
     "output_type": "execute_result",
     "execution_count": 7,
     "data": {
      "text/plain": "32"
     },
     "metadata": {}
    }
   ]
  },
  {
   "metadata": {
    "trusted": true
   },
   "cell_type": "code",
   "source": "# The dataset dosen't have the column name with the feature_names I've created.\ndf = pd.read_csv('wdbc.data', header=None, names=feature_names)",
   "execution_count": 8,
   "outputs": []
  },
  {
   "metadata": {
    "trusted": true
   },
   "cell_type": "code",
   "source": "# Check the head of the dataset\ndf.head()",
   "execution_count": 9,
   "outputs": [
    {
     "output_type": "execute_result",
     "execution_count": 9,
     "data": {
      "text/plain": "         ID Diagnostic  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n0    842302          M        17.99         10.38          122.80     1001.0   \n1    842517          M        20.57         17.77          132.90     1326.0   \n2  84300903          M        19.69         21.25          130.00     1203.0   \n3  84348301          M        11.42         20.38           77.58      386.1   \n4  84358402          M        20.29         14.34          135.10     1297.0   \n\n   smoothness_mean  compactness_mean  concavity_mean  concave_points_mean  \\\n0          0.11840           0.27760          0.3001              0.14710   \n1          0.08474           0.07864          0.0869              0.07017   \n2          0.10960           0.15990          0.1974              0.12790   \n3          0.14250           0.28390          0.2414              0.10520   \n4          0.10030           0.13280          0.1980              0.10430   \n\n   ...  radius_worst  texture_worst  perimeter_worst  area_worst  \\\n0  ...         25.38          17.33           184.60      2019.0   \n1  ...         24.99          23.41           158.80      1956.0   \n2  ...         23.57          25.53           152.50      1709.0   \n3  ...         14.91          26.50            98.87       567.7   \n4  ...         22.54          16.67           152.20      1575.0   \n\n   smoothness_worst  compactness_worst  concavity_worst  concave_points_worst  \\\n0            0.1622             0.6656           0.7119                0.2654   \n1            0.1238             0.1866           0.2416                0.1860   \n2            0.1444             0.4245           0.4504                0.2430   \n3            0.2098             0.8663           0.6869                0.2575   \n4            0.1374             0.2050           0.4000                0.1625   \n\n   symmetry_worst  fractal dimension_worst  \n0          0.4601                  0.11890  \n1          0.2750                  0.08902  \n2          0.3613                  0.08758  \n3          0.6638                  0.17300  \n4          0.2364                  0.07678  \n\n[5 rows x 32 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ID</th>\n      <th>Diagnostic</th>\n      <th>radius_mean</th>\n      <th>texture_mean</th>\n      <th>perimeter_mean</th>\n      <th>area_mean</th>\n      <th>smoothness_mean</th>\n      <th>compactness_mean</th>\n      <th>concavity_mean</th>\n      <th>concave_points_mean</th>\n      <th>...</th>\n      <th>radius_worst</th>\n      <th>texture_worst</th>\n      <th>perimeter_worst</th>\n      <th>area_worst</th>\n      <th>smoothness_worst</th>\n      <th>compactness_worst</th>\n      <th>concavity_worst</th>\n      <th>concave_points_worst</th>\n      <th>symmetry_worst</th>\n      <th>fractal dimension_worst</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>842302</td>\n      <td>M</td>\n      <td>17.99</td>\n      <td>10.38</td>\n      <td>122.80</td>\n      <td>1001.0</td>\n      <td>0.11840</td>\n      <td>0.27760</td>\n      <td>0.3001</td>\n      <td>0.14710</td>\n      <td>...</td>\n      <td>25.38</td>\n      <td>17.33</td>\n      <td>184.60</td>\n      <td>2019.0</td>\n      <td>0.1622</td>\n      <td>0.6656</td>\n      <td>0.7119</td>\n      <td>0.2654</td>\n      <td>0.4601</td>\n      <td>0.11890</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>842517</td>\n      <td>M</td>\n      <td>20.57</td>\n      <td>17.77</td>\n      <td>132.90</td>\n      <td>1326.0</td>\n      <td>0.08474</td>\n      <td>0.07864</td>\n      <td>0.0869</td>\n      <td>0.07017</td>\n      <td>...</td>\n      <td>24.99</td>\n      <td>23.41</td>\n      <td>158.80</td>\n      <td>1956.0</td>\n      <td>0.1238</td>\n      <td>0.1866</td>\n      <td>0.2416</td>\n      <td>0.1860</td>\n      <td>0.2750</td>\n      <td>0.08902</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>84300903</td>\n      <td>M</td>\n      <td>19.69</td>\n      <td>21.25</td>\n      <td>130.00</td>\n      <td>1203.0</td>\n      <td>0.10960</td>\n      <td>0.15990</td>\n      <td>0.1974</td>\n      <td>0.12790</td>\n      <td>...</td>\n      <td>23.57</td>\n      <td>25.53</td>\n      <td>152.50</td>\n      <td>1709.0</td>\n      <td>0.1444</td>\n      <td>0.4245</td>\n      <td>0.4504</td>\n      <td>0.2430</td>\n      <td>0.3613</td>\n      <td>0.08758</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>84348301</td>\n      <td>M</td>\n      <td>11.42</td>\n      <td>20.38</td>\n      <td>77.58</td>\n      <td>386.1</td>\n      <td>0.14250</td>\n      <td>0.28390</td>\n      <td>0.2414</td>\n      <td>0.10520</td>\n      <td>...</td>\n      <td>14.91</td>\n      <td>26.50</td>\n      <td>98.87</td>\n      <td>567.7</td>\n      <td>0.2098</td>\n      <td>0.8663</td>\n      <td>0.6869</td>\n      <td>0.2575</td>\n      <td>0.6638</td>\n      <td>0.17300</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>84358402</td>\n      <td>M</td>\n      <td>20.29</td>\n      <td>14.34</td>\n      <td>135.10</td>\n      <td>1297.0</td>\n      <td>0.10030</td>\n      <td>0.13280</td>\n      <td>0.1980</td>\n      <td>0.10430</td>\n      <td>...</td>\n      <td>22.54</td>\n      <td>16.67</td>\n      <td>152.20</td>\n      <td>1575.0</td>\n      <td>0.1374</td>\n      <td>0.2050</td>\n      <td>0.4000</td>\n      <td>0.1625</td>\n      <td>0.2364</td>\n      <td>0.07678</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows Ã— 32 columns</p>\n</div>"
     },
     "metadata": {}
    }
   ]
  },
  {
   "metadata": {
    "trusted": true
   },
   "cell_type": "code",
   "source": "# Check the info of the dataset\ndf.info()",
   "execution_count": 10,
   "outputs": [
    {
     "output_type": "stream",
     "text": "<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 569 entries, 0 to 568\nData columns (total 32 columns):\n #   Column                   Non-Null Count  Dtype  \n---  ------                   --------------  -----  \n 0   ID                       569 non-null    int64  \n 1   Diagnostic               569 non-null    object \n 2   radius_mean              569 non-null    float64\n 3   texture_mean             569 non-null    float64\n 4   perimeter_mean           569 non-null    float64\n 5   area_mean                569 non-null    float64\n 6   smoothness_mean          569 non-null    float64\n 7   compactness_mean         569 non-null    float64\n 8   concavity_mean           569 non-null    float64\n 9   concave_points_mean      569 non-null    float64\n 10  symmetry_mean            569 non-null    float64\n 11  fractal dimension_mean   569 non-null    float64\n 12  radius_SE                569 non-null    float64\n 13  texture_SE               569 non-null    float64\n 14  perimeter_SE             569 non-null    float64\n 15  area_SE                  569 non-null    float64\n 16  smoothness_SE            569 non-null    float64\n 17  compactness_SE           569 non-null    float64\n 18  concavity_SE             569 non-null    float64\n 19  concave_points_SE        569 non-null    float64\n 20  symmetry_SE              569 non-null    float64\n 21  fractal dimension_SE     569 non-null    float64\n 22  radius_worst             569 non-null    float64\n 23  texture_worst            569 non-null    float64\n 24  perimeter_worst          569 non-null    float64\n 25  area_worst               569 non-null    float64\n 26  smoothness_worst         569 non-null    float64\n 27  compactness_worst        569 non-null    float64\n 28  concavity_worst          569 non-null    float64\n 29  concave_points_worst     569 non-null    float64\n 30  symmetry_worst           569 non-null    float64\n 31  fractal dimension_worst  569 non-null    float64\ndtypes: float64(30), int64(1), object(1)\nmemory usage: 142.4+ KB\n",
     "name": "stdout"
    }
   ]
  },
  {
   "metadata": {
    "trusted": true
   },
   "cell_type": "code",
   "source": "# Convert 'Diagonostic' column to binary\ndf['Diagnostic_num'] = df['Diagnostic'].map({'M':1, 'B':0})\n\n# Check the head of df\ndf.head()",
   "execution_count": 11,
   "outputs": [
    {
     "output_type": "execute_result",
     "execution_count": 11,
     "data": {
      "text/plain": "         ID Diagnostic  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n0    842302          M        17.99         10.38          122.80     1001.0   \n1    842517          M        20.57         17.77          132.90     1326.0   \n2  84300903          M        19.69         21.25          130.00     1203.0   \n3  84348301          M        11.42         20.38           77.58      386.1   \n4  84358402          M        20.29         14.34          135.10     1297.0   \n\n   smoothness_mean  compactness_mean  concavity_mean  concave_points_mean  \\\n0          0.11840           0.27760          0.3001              0.14710   \n1          0.08474           0.07864          0.0869              0.07017   \n2          0.10960           0.15990          0.1974              0.12790   \n3          0.14250           0.28390          0.2414              0.10520   \n4          0.10030           0.13280          0.1980              0.10430   \n\n   ...  texture_worst  perimeter_worst  area_worst  smoothness_worst  \\\n0  ...          17.33           184.60      2019.0            0.1622   \n1  ...          23.41           158.80      1956.0            0.1238   \n2  ...          25.53           152.50      1709.0            0.1444   \n3  ...          26.50            98.87       567.7            0.2098   \n4  ...          16.67           152.20      1575.0            0.1374   \n\n   compactness_worst  concavity_worst  concave_points_worst  symmetry_worst  \\\n0             0.6656           0.7119                0.2654          0.4601   \n1             0.1866           0.2416                0.1860          0.2750   \n2             0.4245           0.4504                0.2430          0.3613   \n3             0.8663           0.6869                0.2575          0.6638   \n4             0.2050           0.4000                0.1625          0.2364   \n\n   fractal dimension_worst  Diagnostic_num  \n0                  0.11890               1  \n1                  0.08902               1  \n2                  0.08758               1  \n3                  0.17300               1  \n4                  0.07678               1  \n\n[5 rows x 33 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ID</th>\n      <th>Diagnostic</th>\n      <th>radius_mean</th>\n      <th>texture_mean</th>\n      <th>perimeter_mean</th>\n      <th>area_mean</th>\n      <th>smoothness_mean</th>\n      <th>compactness_mean</th>\n      <th>concavity_mean</th>\n      <th>concave_points_mean</th>\n      <th>...</th>\n      <th>texture_worst</th>\n      <th>perimeter_worst</th>\n      <th>area_worst</th>\n      <th>smoothness_worst</th>\n      <th>compactness_worst</th>\n      <th>concavity_worst</th>\n      <th>concave_points_worst</th>\n      <th>symmetry_worst</th>\n      <th>fractal dimension_worst</th>\n      <th>Diagnostic_num</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>842302</td>\n      <td>M</td>\n      <td>17.99</td>\n      <td>10.38</td>\n      <td>122.80</td>\n      <td>1001.0</td>\n      <td>0.11840</td>\n      <td>0.27760</td>\n      <td>0.3001</td>\n      <td>0.14710</td>\n      <td>...</td>\n      <td>17.33</td>\n      <td>184.60</td>\n      <td>2019.0</td>\n      <td>0.1622</td>\n      <td>0.6656</td>\n      <td>0.7119</td>\n      <td>0.2654</td>\n      <td>0.4601</td>\n      <td>0.11890</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>842517</td>\n      <td>M</td>\n      <td>20.57</td>\n      <td>17.77</td>\n      <td>132.90</td>\n      <td>1326.0</td>\n      <td>0.08474</td>\n      <td>0.07864</td>\n      <td>0.0869</td>\n      <td>0.07017</td>\n      <td>...</td>\n      <td>23.41</td>\n      <td>158.80</td>\n      <td>1956.0</td>\n      <td>0.1238</td>\n      <td>0.1866</td>\n      <td>0.2416</td>\n      <td>0.1860</td>\n      <td>0.2750</td>\n      <td>0.08902</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>84300903</td>\n      <td>M</td>\n      <td>19.69</td>\n      <td>21.25</td>\n      <td>130.00</td>\n      <td>1203.0</td>\n      <td>0.10960</td>\n      <td>0.15990</td>\n      <td>0.1974</td>\n      <td>0.12790</td>\n      <td>...</td>\n      <td>25.53</td>\n      <td>152.50</td>\n      <td>1709.0</td>\n      <td>0.1444</td>\n      <td>0.4245</td>\n      <td>0.4504</td>\n      <td>0.2430</td>\n      <td>0.3613</td>\n      <td>0.08758</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>84348301</td>\n      <td>M</td>\n      <td>11.42</td>\n      <td>20.38</td>\n      <td>77.58</td>\n      <td>386.1</td>\n      <td>0.14250</td>\n      <td>0.28390</td>\n      <td>0.2414</td>\n      <td>0.10520</td>\n      <td>...</td>\n      <td>26.50</td>\n      <td>98.87</td>\n      <td>567.7</td>\n      <td>0.2098</td>\n      <td>0.8663</td>\n      <td>0.6869</td>\n      <td>0.2575</td>\n      <td>0.6638</td>\n      <td>0.17300</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>84358402</td>\n      <td>M</td>\n      <td>20.29</td>\n      <td>14.34</td>\n      <td>135.10</td>\n      <td>1297.0</td>\n      <td>0.10030</td>\n      <td>0.13280</td>\n      <td>0.1980</td>\n      <td>0.10430</td>\n      <td>...</td>\n      <td>16.67</td>\n      <td>152.20</td>\n      <td>1575.0</td>\n      <td>0.1374</td>\n      <td>0.2050</td>\n      <td>0.4000</td>\n      <td>0.1625</td>\n      <td>0.2364</td>\n      <td>0.07678</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows Ã— 33 columns</p>\n</div>"
     },
     "metadata": {}
    }
   ]
  },
  {
   "metadata": {
    "trusted": true
   },
   "cell_type": "code",
   "source": "# Count the value of the num_column to verfy whether the conversion worked well or not\n\ndf['Diagnostic_num'].value_counts()",
   "execution_count": 12,
   "outputs": [
    {
     "output_type": "execute_result",
     "execution_count": 12,
     "data": {
      "text/plain": "0    357\n1    212\nName: Diagnostic_num, dtype: int64"
     },
     "metadata": {}
    }
   ]
  },
  {
   "metadata": {
    "trusted": true
   },
   "cell_type": "code",
   "source": "# ID isn't important. So drop it\ndf.drop('ID', axis=1, inplace =True)",
   "execution_count": 13,
   "outputs": []
  },
  {
   "metadata": {
    "trusted": true
   },
   "cell_type": "code",
   "source": "# Check the dataset again\ndf.info()",
   "execution_count": 14,
   "outputs": [
    {
     "output_type": "stream",
     "text": "<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 569 entries, 0 to 568\nData columns (total 32 columns):\n #   Column                   Non-Null Count  Dtype  \n---  ------                   --------------  -----  \n 0   Diagnostic               569 non-null    object \n 1   radius_mean              569 non-null    float64\n 2   texture_mean             569 non-null    float64\n 3   perimeter_mean           569 non-null    float64\n 4   area_mean                569 non-null    float64\n 5   smoothness_mean          569 non-null    float64\n 6   compactness_mean         569 non-null    float64\n 7   concavity_mean           569 non-null    float64\n 8   concave_points_mean      569 non-null    float64\n 9   symmetry_mean            569 non-null    float64\n 10  fractal dimension_mean   569 non-null    float64\n 11  radius_SE                569 non-null    float64\n 12  texture_SE               569 non-null    float64\n 13  perimeter_SE             569 non-null    float64\n 14  area_SE                  569 non-null    float64\n 15  smoothness_SE            569 non-null    float64\n 16  compactness_SE           569 non-null    float64\n 17  concavity_SE             569 non-null    float64\n 18  concave_points_SE        569 non-null    float64\n 19  symmetry_SE              569 non-null    float64\n 20  fractal dimension_SE     569 non-null    float64\n 21  radius_worst             569 non-null    float64\n 22  texture_worst            569 non-null    float64\n 23  perimeter_worst          569 non-null    float64\n 24  area_worst               569 non-null    float64\n 25  smoothness_worst         569 non-null    float64\n 26  compactness_worst        569 non-null    float64\n 27  concavity_worst          569 non-null    float64\n 28  concave_points_worst     569 non-null    float64\n 29  symmetry_worst           569 non-null    float64\n 30  fractal dimension_worst  569 non-null    float64\n 31  Diagnostic_num           569 non-null    int64  \ndtypes: float64(30), int64(1), object(1)\nmemory usage: 142.4+ KB\n",
     "name": "stdout"
    }
   ]
  },
  {
   "metadata": {
    "trusted": true
   },
   "cell_type": "code",
   "source": "#Judging form the website and .info, the dataset seems to be clean. So I'm going to split the data.",
   "execution_count": 15,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "raw",
   "source": "Is it okay that I said the data is clean or should I do something about it?"
  },
  {
   "metadata": {
    "trusted": true
   },
   "cell_type": "code",
   "source": "# Split the dataset into features and target\nX = df.drop(['Diagnostic_num', 'Diagnostic'], axis=1)\n\ny = df['Diagnostic_num']",
   "execution_count": 16,
   "outputs": []
  },
  {
   "metadata": {
    "trusted": true
   },
   "cell_type": "code",
   "source": "# Check X\nX.info()",
   "execution_count": 19,
   "outputs": [
    {
     "output_type": "stream",
     "text": "<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 569 entries, 0 to 568\nData columns (total 30 columns):\n #   Column                   Non-Null Count  Dtype  \n---  ------                   --------------  -----  \n 0   radius_mean              569 non-null    float64\n 1   texture_mean             569 non-null    float64\n 2   perimeter_mean           569 non-null    float64\n 3   area_mean                569 non-null    float64\n 4   smoothness_mean          569 non-null    float64\n 5   compactness_mean         569 non-null    float64\n 6   concavity_mean           569 non-null    float64\n 7   concave_points_mean      569 non-null    float64\n 8   symmetry_mean            569 non-null    float64\n 9   fractal dimension_mean   569 non-null    float64\n 10  radius_SE                569 non-null    float64\n 11  texture_SE               569 non-null    float64\n 12  perimeter_SE             569 non-null    float64\n 13  area_SE                  569 non-null    float64\n 14  smoothness_SE            569 non-null    float64\n 15  compactness_SE           569 non-null    float64\n 16  concavity_SE             569 non-null    float64\n 17  concave_points_SE        569 non-null    float64\n 18  symmetry_SE              569 non-null    float64\n 19  fractal dimension_SE     569 non-null    float64\n 20  radius_worst             569 non-null    float64\n 21  texture_worst            569 non-null    float64\n 22  perimeter_worst          569 non-null    float64\n 23  area_worst               569 non-null    float64\n 24  smoothness_worst         569 non-null    float64\n 25  compactness_worst        569 non-null    float64\n 26  concavity_worst          569 non-null    float64\n 27  concave_points_worst     569 non-null    float64\n 28  symmetry_worst           569 non-null    float64\n 29  fractal dimension_worst  569 non-null    float64\ndtypes: float64(30)\nmemory usage: 133.5 KB\n",
     "name": "stdout"
    }
   ]
  },
  {
   "metadata": {
    "trusted": true
   },
   "cell_type": "code",
   "source": "# Check y\ny.info()",
   "execution_count": 21,
   "outputs": [
    {
     "output_type": "stream",
     "text": "<class 'pandas.core.series.Series'>\nRangeIndex: 569 entries, 0 to 568\nSeries name: Diagnostic_num\nNon-Null Count  Dtype\n--------------  -----\n569 non-null    int64\ndtypes: int64(1)\nmemory usage: 4.6 KB\n",
     "name": "stdout"
    }
   ]
  },
  {
   "metadata": {
    "trusted": true
   },
   "cell_type": "code",
   "source": "#Split the data\nfrom sklearn.model_selection import train_test_split",
   "execution_count": 22,
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.4",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}